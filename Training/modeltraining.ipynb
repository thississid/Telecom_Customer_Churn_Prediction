{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  State  Account length  Area code International plan Voice mail plan  \\\n",
      "0    KS             128        415                 No             Yes   \n",
      "1    OH             107        415                 No             Yes   \n",
      "2    NJ             137        415                 No              No   \n",
      "3    OH              84        408                Yes              No   \n",
      "4    OK              75        415                Yes              No   \n",
      "\n",
      "   Number vmail messages  Total day minutes  Total day calls  \\\n",
      "0                     25              265.1              110   \n",
      "1                     26              161.6              123   \n",
      "2                      0              243.4              114   \n",
      "3                      0              299.4               71   \n",
      "4                      0              166.7              113   \n",
      "\n",
      "   Total day charge  Total eve minutes  Total eve calls  Total eve charge  \\\n",
      "0             45.07              197.4               99             16.78   \n",
      "1             27.47              195.5              103             16.62   \n",
      "2             41.38              121.2              110             10.30   \n",
      "3             50.90               61.9               88              5.26   \n",
      "4             28.34              148.3              122             12.61   \n",
      "\n",
      "   Total night minutes  Total night calls  Total night charge  \\\n",
      "0                244.7                 91               11.01   \n",
      "1                254.4                103               11.45   \n",
      "2                162.6                104                7.32   \n",
      "3                196.9                 89                8.86   \n",
      "4                186.9                121                8.41   \n",
      "\n",
      "   Total intl minutes  Total intl calls  Total intl charge  \\\n",
      "0                10.0                 3               2.70   \n",
      "1                13.7                 3               3.70   \n",
      "2                12.2                 5               3.29   \n",
      "3                 6.6                 7               1.78   \n",
      "4                10.1                 3               2.73   \n",
      "\n",
      "   Customer service calls  Churn  \n",
      "0                       1  False  \n",
      "1                       1  False  \n",
      "2                       0  False  \n",
      "3                       2  False  \n",
      "4                       3  False  \n",
      "logistic_regression metrics saved!\n",
      "random_forest metrics saved!\n",
      "Models and metrics saved!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '/Users/siddarthayadav/Code/Telecom_Customer_Churn_Prediction/Dataset/churn-bigml-80.csv'  # Update with your dataset path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Check the first few rows\n",
    "print(df.head())\n",
    "\n",
    "# Drop irrelevant columns if they exist\n",
    "if 'customerID' in df.columns:\n",
    "    df.drop(['customerID'], axis=1, inplace=True)\n",
    "\n",
    "# Handle missing values\n",
    "df.replace(\" \", np.nan, inplace=True)\n",
    "df.fillna(df.median(numeric_only=True), inplace=True)\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for column in df.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    df[column] = le.fit_transform(df[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop('Churn', axis=1)\n",
    "y = df['Churn']\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Train Logistic Regression\n",
    "logistic_model = LogisticRegression(random_state=42)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred_logistic = logistic_model.predict(X_test)\n",
    "\n",
    "# Train Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate and Save Model Performance Metrics\n",
    "def save_metrics(y_test, y_pred, model_name):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"classification_report\": report,\n",
    "        \"confusion_matrix\": confusion.tolist()  # Convert to list for JSON saving\n",
    "    }\n",
    "\n",
    "    with open(f'{model_name}_metrics.txt', 'w') as f:\n",
    "        f.write(f\"Model: {model_name}\\n\")\n",
    "        f.write(f\"Accuracy: {accuracy}\\n\\n\")\n",
    "        f.write(\"Classification Report:\\n\")\n",
    "        f.write(report)\n",
    "        f.write(\"\\nConfusion Matrix:\\n\")\n",
    "        f.write(str(confusion))\n",
    "\n",
    "    print(f\"{model_name} metrics saved!\")\n",
    "\n",
    "# Save performance metrics\n",
    "save_metrics(y_test, y_pred_logistic, \"logistic_regression\")\n",
    "save_metrics(y_test, y_pred_rf, \"random_forest\")\n",
    "\n",
    "# Save models\n",
    "joblib.dump(logistic_model, 'logistic_model.pkl')\n",
    "joblib.dump(rf_model, 'random_forest_model.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "print(\"Models and metrics saved!\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Now is the deep learning Approach\n"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T15:43:41.609858Z",
     "start_time": "2025-04-29T15:43:41.595657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '/Users/siddarthayadav/Desktop/Telecom_Customer_Churn_Prediction/Dataset/churn-bigml-80.csv'  # Update if necessary\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop irrelevant columns if they exist\n",
    "if 'customerID' in df.columns:\n",
    "    df.drop(['customerID'], axis=1, inplace=True)\n",
    "\n",
    "# Handle missing values\n",
    "df.replace(\" \", np.nan, inplace=True)\n",
    "df.fillna(df.median(numeric_only=True), inplace=True)\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for column in df.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    df[column] = le.fit_transform(df[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop('Churn', axis=1)\n",
    "y = df['Churn']\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Build Neural Network Model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(\"int32\").flatten()\n",
    "\n",
    "# Evaluate and Save Model Performance Metrics\n",
    "def save_metrics_dl(y_test, y_pred, model_name):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    with open(f'{model_name}_metrics.txt', 'w') as f:\n",
    "        f.write(f\"Model: {model_name}\\n\")\n",
    "        f.write(f\"Accuracy: {accuracy}\\n\\n\")\n",
    "        f.write(\"Classification Report:\\n\")\n",
    "        f.write(report)\n",
    "        f.write(\"\\nConfusion Matrix:\\n\")\n",
    "        f.write(str(confusion))\n",
    "\n",
    "    print(f\"{model_name} metrics saved!\")\n",
    "\n",
    "# Save metrics\n",
    "save_metrics_dl(y_test, y_pred, \"deep_learning_model\")\n",
    "\n",
    "# Save model\n",
    "model.save('deep_learning_model.h5')\n",
    "print(\"Deep Learning Model saved!\")\n"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[20], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Sequential\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlayers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Dense, Dropout\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_selection\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m train_test_split\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'tensorflow.keras'"
     ]
    }
   ],
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tele",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
